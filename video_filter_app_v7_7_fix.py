# video_filter_app_v7_7_fix.py
# Miromi Signature Retro Filter Studio v7.7 â€” fixed+ (color + UI + effects + fast mode)

import streamlit as st
import cv2
import numpy as np
import os, tempfile, math, random

st.set_page_config(page_title="Miromi Retro Filter Studio v7.7", layout="centered")
st.title("ğŸ Miromi Retro Filter Studio â€” v7.7 fixed+")

# ---------------- Paths ----------------
ROOT = os.getcwd()
LUT_DIR = os.path.join(ROOT, "filters")
OVERLAY_DIR = os.path.join(ROOT, "overlays")
NOISE_DIR = os.path.join(ROOT, "noise_videos")

# ---------------- LUT helpers ----------------
def load_cube_lut(path):
    """
    ì½ê¸° ì•ˆì •í˜• CUBE íŒŒì„œ.
    - LUT_3D_SIZE í—¤ë”ë¥¼ ìš°ì„  ì‚¬ìš©
    - ì—†ë‹¤ë©´ ë¼ì¸ìˆ˜ë¡œ size ì¶”ì •
    ë°˜í™˜: (size, size, size, 3) float32 [0..1]
    """
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        rows = []
        size = None
        for line in f:
            s = line.strip()
            if not s or s.startswith("#"):
                continue
            if s.upper().startswith("LUT_3D_SIZE"):
                try:
                    size = int(s.split()[-1])
                except:
                    pass
                continue
            parts = s.split()
            if len(parts) == 3:
                try:
                    r,g,b = map(float, parts)
                    rows.append([r,g,b])
                except:
                    pass
        data = np.array(rows, dtype=np.float32)
        if size is None:
            size = int(round(data.shape[0] ** (1/3)))
        lut = data.reshape(size, size, size, 3)
        lut = np.clip(lut, 0.0, 1.0)
        return lut

def apply_lut_bgr(frame_bgr, lut, channel_order="BGR"):
    """
    v1ì—ì„œ ì˜ ë‚˜ì˜¤ë˜ ë°©ì‹ìœ¼ë¡œ 'BGR ì¸ë±ì‹±' ê¸°ë³¸ ì ìš©.
    ì¼ë¶€ LUTê°€ RGB ì¸ë±ì‹±ì„ ìš”êµ¬í•˜ë©´ channel_order="RGB" ë¡œ ì‚¬ìš©.
    ë°˜í™˜: BGR uint8
    """
    size = lut.shape[0]
    f = frame_bgr.astype(np.float32) / 255.0
    if channel_order == "BGR":
        r = f[...,2]; g = f[...,1]; b = f[...,0]
    else:  # "RGB"
        r = f[...,2]; g = f[...,1]; b = f[...,0]  # ì…ë ¥ì€ BGRì´ë¯€ë¡œ ë¨¼ì € RGB ìˆœì„œë¡œ ë°”ê¿ˆ
        # ìœ„ì™€ ê°™ì§€ë§Œ ê°€ë…ì„±ìš© ë¶„ê¸° ìœ ì§€

    # ìµœê·¼ì ‘ ìƒ˜í”Œ(ë¹ ë¦„)
    ir = np.clip((r * (size-1)).astype(np.int32), 0, size-1)
    ig = np.clip((g * (size-1)).astype(np.int32), 0, size-1)
    ib = np.clip((b * (size-1)).astype(np.int32), 0, size-1)
    mapped = lut[ir, ig, ib]   # RGB ìˆœìœ¼ë¡œ ì €ì¥ëœ LUT ê°’ì„ ì½ìŒ (shape (...,3) in [0..1])

    out = np.empty_like(frame_bgr, dtype=np.uint8)
    # LUTì˜ ì±„ë„ì€ RGB ì´ë¯€ë¡œ BGR ìˆœì„œë¡œ ë˜ëŒë ¤ì„œ ê¸°ë¡
    out[...,0] = np.clip(mapped[...,2] * 255.0, 0, 255).astype(np.uint8)
    out[...,1] = np.clip(mapped[...,1] * 255.0, 0, 255).astype(np.uint8)
    out[...,2] = np.clip(mapped[...,0] * 255.0, 0, 255).astype(np.uint8)
    return out

# ---------------- Overlays ----------------
def apply_overlay_image(frame_bgr, overlay_path, alpha=0.3):
    """
    overlayê°€ PNG(ì•ŒíŒŒ ìˆìŒ)ë©´ ì•ŒíŒŒ ì±„ë„ë¡œ í•©ì„±,
    ê·¸ ì™¸(JPG/PNG ë¬´ì•ŒíŒŒ)ëŠ” ê°€ì¤‘ì¹˜ ë¸”ë Œë“œ.
    alpha: 0~1
    """
    ov = cv2.imread(overlay_path, cv2.IMREAD_UNCHANGED)
    if ov is None: 
        return frame_bgr
    h,w = frame_bgr.shape[:2]
    ov = cv2.resize(ov, (w, h), interpolation=cv2.INTER_LINEAR)

    out = frame_bgr.astype(np.float32)

    if ov.shape[2] == 4:
        rgb = ov[...,:3].astype(np.float32)
        a = (ov[...,3:]/255.0).astype(np.float32) * alpha
        out = (1.0 - a) * out + a * rgb
    else:
        out = cv2.addWeighted(out, 1.0 - alpha, ov.astype(np.float32), alpha, 0.0)

    return np.clip(out, 0, 255).astype(np.uint8)

def apply_noise_video(frame_bgr, cap, mix=0.12):
    """ë…¸ì´ì¦ˆ mp4ë¥¼ í”„ë ˆì„ í¬ê¸°ë¡œ ë§ì¶° ê°€ì¤‘í•©"""
    ok, nf = cap.read()
    if not ok:
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        ok, nf = cap.read()
        if not ok:
            return frame_bgr
    nf = cv2.resize(nf, (frame_bgr.shape[1], frame_bgr.shape[0]), interpolation=cv2.INTER_LINEAR)
    return cv2.addWeighted(frame_bgr, 1.0 - mix, nf, mix, 0)

# ---------------- Extra FX ----------------
def add_grain(frame_bgr, strength=30, fast=False):
    """
    strength: 0~100 ê¶Œì¥. ê°’ì´ í´ìˆ˜ë¡ ê°•í•œ ê·¸ë ˆì¸.
    fast=Trueë©´ ì €í•´ìƒë„ ë…¸ì´ì¦ˆë¥¼ ì—…ìƒ˜í”Œí•´ ì†ë„â†‘(í´ë¼ìš°ë“œìš©)
    """
    h,w = frame_bgr.shape[:2]
    if fast:
        # í° ì…ì ëŠë‚Œì˜ ë¹ ë¥¸ ê·¸ë ˆì¸
        gh, gw = max(32, h//6), max(32, w//6)
        noise_small = np.random.normal(0, 25, (gh, gw, 1)).astype(np.float32)
        noise = cv2.resize(noise_small, (w, h), interpolation=cv2.INTER_LINEAR)
    else:
        noise = np.random.normal(0, 25, (h, w, 1)).astype(np.float32)

    amp = (strength/100.0) * 35.0  # ëŒ€ëµì  ìŠ¤ì¼€ì¼
    out = frame_bgr.astype(np.float32) + amp * noise
    return np.clip(out, 0, 255).astype(np.uint8)

def dream_blur(frame_bgr, strength=4, fast=False):
    """
    ì†Œí”„íŠ¸ ê¸€ë¡œìš° ëŠë‚Œ. strength 0~10 ê¶Œì¥
    """
    sigma = max(0.1, strength) * (1.0 if fast else 1.5)
    blur = cv2.GaussianBlur(frame_bgr, (0,0), sigmaX=sigma, sigmaY=sigma)
    mix = min(0.8, 0.18 + 0.06*strength)  # ì„ëŠ” ë¹„ìœ¨
    return cv2.addWeighted(frame_bgr, 1.0 - mix, blur, mix, 0.0)

# ---------------- UI ----------------
video_file = st.file_uploader("ğŸ¥ ì˜ìƒ ì—…ë¡œë“œ (MP4/MOV/AVI, â‰¤200MB ê¶Œì¥)", type=["mp4","mov","avi","m4v"])

lut_list = ["None"]
if os.path.isdir(LUT_DIR):
    lut_list += [f for f in sorted(os.listdir(LUT_DIR)) if f.lower().endswith(".cube")]

overlay_list = ["None"]
if os.path.isdir(OVERLAY_DIR):
    overlay_list += [f for f in sorted(os.listdir(OVERLAY_DIR)) if f.lower().endswith((".png",".jpg",".jpeg"))]

noise_list = ["None"]
if os.path.isdir(NOISE_DIR):
    noise_list += [f for f in sorted(os.listdir(NOISE_DIR)) if f.lower().endswith((".mp4",".mov",".m4v",".avi"))]

lut_choice = st.selectbox("ğŸ¨ LUT í”„ë¦¬ì…‹", lut_list, index=lut_list.index("None") if "None" in lut_list else 0)

col1, col2 = st.columns(2)
with col1:
    overlay_choice = st.selectbox("ğŸ“¼ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€", overlay_list, index=0)
    overlay_alpha_step = 3  # ê¸°ë³¸ê°’
    if overlay_choice != "None":
        overlay_alpha_step = st.slider("ì˜¤ë²„ë ˆì´ ê°•ë„ (1~10)", 1, 10, 3)
with col2:
    noise_choice = st.selectbox("ğŸŒ«ï¸ ì›€ì§ì´ëŠ” ë…¸ì´ì¦ˆ (MP4)", noise_list, index=0)
    noise_mix = 12
    if noise_choice != "None":
        noise_mix = st.slider("ë…¸ì´ì¦ˆ ê°•ë„ (1~30)", 1, 30, 12)

# â”€â”€ ê¸°ë³¸ ê·¸ë ˆì¸ & ë“œë¦¼ë¸”ëŸ¬ ë³µêµ¬
st.subheader("âœ¨ ì¶”ê°€ íš¨ê³¼")
c1, c2, c3 = st.columns(3)
with c1:
    use_grain = st.checkbox("ğŸ ê¸°ë³¸ ê·¸ë ˆì¸", value=False)
    grain_level = st.slider("ê·¸ë ˆì¸ ê°•ë„", 0, 100, 30) if use_grain else 0
with c2:
    use_dream = st.checkbox("ğŸŒ« ë“œë¦¼ ë¸”ëŸ¬", value=False)
    dream_level = st.slider("ë¸”ëŸ¬ ê°•ë„", 0, 10, 4) if use_dream else 0
with c3:
    # LUT íŒŒë—ê²Œ ë³´ì¼ ë•Œ ì‘ê¸‰ ìŠ¤ìœ„ì¹˜(ì¼ë¶€ RGB ì¸ë±ìŠ¤ LUT ëŒ€ì‘)
    rgb_mode = st.toggle("ğŸ§ª LUT RGB ëª¨ë“œ(íŒŒë—ê²Œ ë³´ì´ë©´ êº¼ë‘ê¸°)", value=False)

fast_mode = st.checkbox("âš¡ ë¹ ë¥¸ ë Œë” (30ì´ˆ ëª©í‘œ)", value=True,
                        help="í•´ìƒë„ ìµœëŒ€ 720pë¡œ ì¶•ì†Œ + FPS ìµœëŒ€ 15 + ë¹ ë¥¸ ê·¸ë ˆì¸/ë¸”ëŸ¬")

go = st.button("ğŸš€ í•„í„° ì ìš©í•˜ê¸°")

# ì„¤ëª…(ìš”ì²­ 2ë²ˆ)
with st.expander("âš¡ ë¹ ë¥¸ ë Œë”ëŠ” ì–´ë–»ê²Œ ë¹ ë¥¸ê°€ìš”?"):
    st.markdown(
        "- **GPUê°€ ì—†ëŠ” í™˜ê²½(ì˜ˆ: Streamlit Cloud)**ì—ì„œë„ ë¹ ë¥´ê²Œ ëŒë¦¬ê¸° ìœ„í•´ ì•„ë˜ ìµœì í™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n"
        "  1) **í•´ìƒë„ ì œí•œ**: ì…ë ¥ ì˜ìƒì„ ìµœëŒ€ 720pë¡œ ì¶•ì†Œí•´ í”½ì…€ ì—°ì‚°ëŸ‰ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.\n"
        "  2) **FPS ì œí•œ**: ì¶œë ¥ FPSë¥¼ ìµœëŒ€ **15fps**ë¡œ ì œí•œí•©ë‹ˆë‹¤.\n"
        "  3) **ê²½ëŸ‰ ì—°ì‚°**: ê·¸ë ˆì¸ì€ ì €í•´ìƒë„ ë…¸ì´ì¦ˆ ì—…ìƒ˜í”Œ, ë¸”ëŸ¬ëŠ” ë‚®ì€ ì‹œê·¸ë§ˆë¡œ ì²˜ë¦¬í•´ ì†ë„ë¥¼ ì˜¬ë¦½ë‹ˆë‹¤.\n"
        "  \nGPUê°€ ìˆëŠ” ë¡œì»¬ PCì—ì„œëŠ” ì²´í¬ë¥¼ ë„ë©´ ì›ë³¸ í•´ìƒë„Â·FPSë¡œ ë” ê³ í’ˆì§ˆ ì¶œë ¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )

# ---------------- Processing ----------------
if go and video_file is not None:
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as f:
        f.write(video_file.read())
        src_path = f.name

    cap = cv2.VideoCapture(src_path)
    fps = max(1.0, cap.get(cv2.CAP_PROP_FPS))
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Fast mode: í•´ìƒë„ & FPS ì œí•œ
    target_fps = min(fps, 15.0) if fast_mode else fps
    scale = 1.0
    if fast_mode:
        max_side = 720
        side = max(width, height)
        if side > max_side:
            scale = max_side / side
    out_w = max(16, int(round(width * scale / 2))*2)
    out_h = max(16, int(round(height * scale / 2))*2)

    # ì¶œë ¥ ì¤€ë¹„
    out_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter(out_path, fourcc, target_fps, (out_w, out_h))

    # LUT ë¯¸ë¦¬ ë¡œë“œ
    lut = None
    if lut_choice != "None":
        try:
            lut = load_cube_lut(os.path.join(LUT_DIR, lut_choice))
        except Exception as e:
            st.error(f"LUT ë¡œë“œ ì˜¤ë¥˜: {e}")
            lut = None

    # ë…¸ì´ì¦ˆ ë¹„ë””ì˜¤ í•¸ë“¤
    noise_cap = None
    if noise_choice != "None":
        p = os.path.join(NOISE_DIR, noise_choice)
        if os.path.exists(p):
            noise_cap = cv2.VideoCapture(p)

    progress = st.progress(0)
    done = 0

    while True:
        ok, frame = cap.read()
        if not ok:
            break

        # ë¦¬ì‚¬ì´ì¦ˆ(ë¹ ë¥¸ ë Œë”ìš©)
        if scale != 1.0:
            frame = cv2.resize(frame, (out_w, out_h), interpolation=cv2.INTER_AREA)

        # 1) LUT (BGR ì¸ë±ì‹± ê¸°ë³¸) â€” v1ê³¼ ë™ì¼ íŒŒì´í”„ë¼ì¸ -> íŒŒë—ê²Œ ë‚˜ì˜¤ëŠ” ë¬¸ì œ í•´ê²°
        if lut is not None:
            frame = apply_lut_bgr(frame, lut, channel_order="RGB" if rgb_mode else "BGR")

        # 2) ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
        if overlay_choice != "None":
            alpha = max(0.1, min(1.0, overlay_alpha_step / 10.0))
            frame = apply_overlay_image(frame, os.path.join(OVERLAY_DIR, overlay_choice), alpha=alpha)

        # 3) ì›€ì§ì´ëŠ” ë…¸ì´ì¦ˆ
        if noise_cap is not None:
            frame = apply_noise_video(frame, noise_cap, mix=noise_mix/100.0)

        # 4) ê·¸ë ˆì¸ / ë“œë¦¼ë¸”ëŸ¬
        if use_grain and grain_level > 0:
            frame = add_grain(frame, grain_level, fast=fast_mode)
        if use_dream and dream_level > 0:
            frame = dream_blur(frame, dream_level, fast=fast_mode)

        writer.write(frame)
        done += 1
        progress.progress(min(1.0, done / max(1, total)))

    cap.release()
    writer.release()
    if noise_cap is not None:
        noise_cap.release()

    st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
    st.video(out_path)
    st.download_button(
        "ğŸ’¾ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
        data=open(out_path, "rb").read(),
        file_name=f"Miromi_v7.7_{os.path.splitext(lut_choice)[0] or 'None'}.mp4",
        mime="video/mp4"
    )

elif go and video_file is None:
    st.warning("ğŸ“ ë¨¼ì € ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
