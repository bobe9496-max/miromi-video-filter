@ -1,106 +1,106 @@
# ======================================
# Miromi Retro Filter  (Streamlit)
# Developed by THE PLATFORM COMPANY
# ======================================
import streamlit as st
import cv2
import numpy as np
import os
import tempfile

st.set_page_config(page_title="Miromi Retro Filter", layout="centered")
st.title("ğŸ Miromi Retro Filter")
st.caption("Developed by THE PLATFORM COMPANY")

# --- Project folders ---
ROOT = os.getcwd()
LUT_DIR      = os.path.join(ROOT, "filters")
OVERLAY_DIR  = os.path.join(ROOT, "overlays")
NOISE_DIR    = os.path.join(ROOT, "noise_videos")
for d in [LUT_DIR, OVERLAY_DIR, NOISE_DIR]:
    os.makedirs(d, exist_ok=True)

# ---------- LUT loader (LUT_3D_SIZE ê¸°ë°˜, v1 í˜¸í™˜) ----------
def load_cube_lut(path: str) -> np.ndarray:
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        lines = [ln.strip() for ln in f if ln.strip() and not ln.strip().startswith("#")]

    size = None
    for ln in lines:
        if ln.upper().startswith("LUT_3D_SIZE"):
            size = int(ln.split()[-1])
            break
    if size is None:
        raise ValueError("LUT_3D_SIZE not found in: " + path)

    triplets = []
    for ln in lines:
        parts = ln.split()
        if len(parts) == 3:
            try:
                triplets.append([float(parts[0]), float(parts[1]), float(parts[2])])
            except Exception:
                pass
    data = np.asarray(triplets, dtype=np.float32)
    if data.size != size * size * size * 3:
        raise ValueError(f"Cube data size mismatch. expected {size**3} rows, got {data.shape[0]}")
    lut = data.reshape(size, size, size, 3)
    if lut.max() > 1.001:  # 0..255 í˜•íƒœì¼ ë•Œ ì •ê·œí™”
        lut = lut / 255.0
    return np.clip(lut, 0.0, 1.0).astype(np.float32)

# ---------- LUT apply (ê¸°ë³¸ BGR, RGB ì˜µì…˜) ----------
def apply_lut(frame_bgr: np.ndarray, lut: np.ndarray, order: str = "BGR") -> np.ndarray:
    size = lut.shape[0]
    bgr = frame_bgr.astype(np.float32) / 255.0
    b, g, r = cv2.split(bgr)
    ib = np.clip((b * (size - 1)).astype(np.int32), 0, size - 1)
    ig = np.clip((g * (size - 1)).astype(np.int32), 0, size - 1)
    ir = np.clip((r * (size - 1)).astype(np.int32), 0, size - 1)

    if order == "RGB":
        mapped_rgb = lut[ir, ig, ib]      # ì§„ì§œ RGB LUTì¼ ë•Œ
    else:  # "BGR" (v1 ê¸°ë³¸ ë™ì‘)
        mapped_rgb = lut[ib, ig, ir]

    mapped_u8 = (np.clip(mapped_rgb, 0.0, 1.0) * 255.0 + 0.5).astype(np.uint8)
    return cv2.cvtColor(mapped_u8, cv2.COLOR_RGB2BGR)

# ---------- Static overlay (PNG/JPG, ì•ŒíŒŒ ì§€ì›) ----------
def apply_overlay(frame_bgr: np.ndarray, overlay_path: str, alpha: float) -> np.ndarray:
    ov = cv2.imread(overlay_path, cv2.IMREAD_UNCHANGED)
    if ov is None:
        return frame_bgr
    ov = cv2.resize(ov, (frame_bgr.shape[1], frame_bgr.shape[0]))
    out = frame_bgr.astype(np.float32)

    if ov.shape[2] == 4:
        rgb = ov[:, :, :3].astype(np.float32)
        a   = (ov[:, :, 3:4].astype(np.float32) / 255.0) * alpha
        out = (1.0 - a) * out + a * rgb
    else:
        out = cv2.addWeighted(out, 1.0 - alpha, ov.astype(np.float32), alpha, 0.0)
    return np.clip(out, 0, 255).astype(np.uint8)

# ---------- Moving noise (video) ----------
def apply_moving_noise(frame_bgr: np.ndarray, noise_cap, strength: float):
    if noise_cap is None:
        return frame_bgr
    ret, nf = noise_cap.read()
    if not ret:
        noise_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        ret, nf = noise_cap.read()
        if not ret:
            return frame_bgr
    nf = cv2.resize(nf, (frame_bgr.shape[1], frame_bgr.shape[0]))
    return cv2.addWeighted(frame_bgr, 1.0 - strength, nf, strength, 0.0)

# ---------- Film grain (procedural) ----------
def apply_film_grain(frame_bgr: np.ndarray, intensity: float) -> np.ndarray:
    if intensity <= 0:
        return frame_bgr
    h, w = frame_bgr.shape[:2]
    noise = np.random.normal(0, 25 * intensity, (h, w, 1)).astype(np.float32)  # ë‹¨ì¼ ì±„ë„ ë…¸ì´ì¦ˆ
    noise = np.random.normal(0, 25 * intensity, (h, w, 1)).astype(np.float32)
    noise = np.repeat(noise, 3, axis=2)
    out = frame_bgr.astype(np.float32) + noise
    return np.clip(out, 0, 255).astype(np.uint8)
@ -111,11 +111,37 @@ def apply_dream_blur(frame_bgr: np.ndarray, amount: int) -> np.ndarray:
        return frame_bgr
    k = amount * 2 + 1   # í™€ìˆ˜ ì»¤ë„
    blurred = cv2.GaussianBlur(frame_bgr, (k, k), 0)
    # ì†Œí”„íŠ¸ ë¸”ë Œë“œ
    alpha = min(0.8, 0.06 * amount)
    out = cv2.addWeighted(frame_bgr, 1.0 - alpha, blurred, alpha, 0.0)
    return out

# ---------- Previews (overlay & noise thumbnails) ----------
@st.cache_data(show_spinner=False)
def load_overlay_preview(path: str, max_w=480) -> np.ndarray:
    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)
    if img is None:
        return None
    if img.shape[2] == 4:
        img = img[:, :, :3]
    if img.shape[1] > max_w:
        scale = max_w / img.shape[1]
        img = cv2.resize(img, (int(img.shape[1] * scale), int(img.shape[0] * scale)))
    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

@st.cache_data(show_spinner=False)
def load_noise_first_frame(path: str, max_w=480) -> np.ndarray:
    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        return None
    ret, frame = cap.read()
    cap.release()
    if not ret or frame is None:
        return None
    if frame.shape[1] > max_w:
        scale = max_w / frame.shape[1]
        frame = cv2.resize(frame, (int(frame.shape[1] * scale), int(frame.shape[0] * scale)))
    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

# ---------- UI ----------
video = st.file_uploader("ğŸ¥ ì˜ìƒ ì—…ë¡œë“œ (MP4/MOV/AVI, â‰¤ 200MB)", type=["mp4", "mov", "avi"])

@ -134,10 +160,20 @@ with col1:
    overlay_name = st.selectbox("ì •ì§€ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€", ["None"] + overlay_list, index=0)
    overlay_alpha_step = st.slider("ì˜¤ë²„ë ˆì´ ê°•ë„ (1â€“10)", 1, 10, 3)
    overlay_alpha = overlay_alpha_step / 10.0
    # --- overlay preview ---
    if overlay_name != "None":
        ov_img = load_overlay_preview(os.path.join(OVERLAY_DIR, overlay_name))
        if ov_img is not None:
            st.image(ov_img, caption=f"Overlay: {overlay_name}", use_container_width=True)
with col2:
    noise_name = st.selectbox("ì›€ì§ì´ëŠ” ë…¸ì´ì¦ˆ(ë¹„ë””ì˜¤)", ["None"] + noise_list, index=0)
    noise_strength_step = st.slider("ë…¸ì´ì¦ˆ ê°•ë„ (1â€“10)", 1, 10, 2)
    noise_strength = noise_strength_step / 10.0
    # --- noise thumbnail (first frame) ---
    if noise_name != "None":
        nf = load_noise_first_frame(os.path.join(NOISE_DIR, noise_name))
        if nf is not None:
            st.image(nf, caption=f"Noise preview (first frame): {noise_name}", use_container_width=True)

st.subheader("âœ¨ ì¶”ê°€ íš¨ê³¼")
col3, col4 = st.columns(2)
@ -149,8 +185,8 @@ with col4:

st.subheader("âš¡ ë¹ ë¥¸ ë Œë”")
fast_mode = st.checkbox("ë¹ ë¥¸ ë Œë” (ê¶Œì¥)", value=True,
                        help="FPSë¥¼ ìµœëŒ€ 15ë¡œ ì œí•œí•´ ì „ì²´ í”„ë ˆì„ ìˆ˜ë¥¼ ì¤„ì—¬ CPU ì²˜ë¦¬ëŸ‰ì„ ë‚®ì¶¥ë‹ˆë‹¤. "
                             "í•´ìƒë„ëŠ” ìœ ì§€ë˜ë©°, Streamlit CloudëŠ” GPUê°€ ì—†ìœ¼ë¯€ë¡œ CPU ìµœì í™” ë°©ì‹ì…ë‹ˆë‹¤.")
                        help="FPSë¥¼ ìµœëŒ€ 15ë¡œ ì œí•œí•˜ê³  í”„ë ˆì„ ìƒ˜í”Œë§ìœ¼ë¡œ CPU ì²˜ë¦¬ëŸ‰ì„ ë‚®ì¶¥ë‹ˆë‹¤. "
                             "í•´ìƒë„ëŠ” ìœ ì§€. (Streamlit CloudëŠ” GPU ì—†ìŒ â†’ CPU ìµœì í™”)")

run = st.button("ğŸš€ í•„í„° ì ìš©í•˜ê¸°")

@ -170,8 +206,11 @@ if run and video is not None:
        h   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0

        # ë¹ ë¥¸ ë Œë”: FPS cap (ìµœëŒ€ 15)
        # ë¹ ë¥¸ ë Œë”: FPS cap (ìµœëŒ€ 15) + í”„ë ˆì„ ìŠ¤í‚µ
        target_fps = min(15.0, fps) if fast_mode else fps
        frame_skip = 1
        if fast_mode and fps > 15:
            frame_skip = int(round(fps / 15.0))  # ëŒ€ëµ 15fpsë¡œ ìƒ˜í”Œë§

        out_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*"mp4v"), target_fps, (w, h))
@ -193,11 +232,6 @@ if run and video is not None:
        prog = st.progress(0)
        done = 0

        # í”„ë ˆì„ ìŠ¤í‚µ ë¹„ìœ¨ (ë¹ ë¥¸ ë Œë” ì‹œ)
        frame_skip = 1
        if fast_mode and fps > 15:
            frame_skip = int(round(fps / 15.0))  # ëŒ€ëµ 15fpsë¡œ ìƒ˜í”Œë§

        idx = 0
        while True:
            ret, frame = cap.read()
@ -241,10 +275,15 @@ if run and video is not None:
            noise_cap.release()

        st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        st.video(out_path)

        # âœ… í˜ì´ì§€ ë‚´ ë°”ë¡œ ì¬ìƒ(ë‹¤ìš´ ì—†ì´) â€” bytesë¡œ ì „ë‹¬í•˜ë©´ ì•ˆì •ì 
        with open(out_path, "rb") as vf:
            video_bytes = vf.read()
        st.video(video_bytes, format="video/mp4", start_time=0)

        st.download_button(
            "ğŸ’¾ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
            data=open(out_path, "rb").read(),
            data=video_bytes,
            file_name=f"Miromi_{(lut_name if lut_name!='None' else 'NoLUT').replace('.cube','')}.mp4",
            mime="video/mp4",
        )
