# video_filter_app_v7_7_fix.py
# Miromi Retro Filter â€“ Developed by THE PLATFORM COMPANY
import streamlit as st
import cv2
import numpy as np
import tempfile
import os
from pathlib import Path

# --------------------------
# Page / theme (UI ê³ ì •)
# --------------------------
st.set_page_config(page_title="Miromi Retro Filter", page_icon="ğŸ", layout="centered")
st.markdown("""
<style>
/* ë³¸ë¬¸ í­ ê³ ì • */
.block-container {max-width: 900px !important;}
/* ìœ„Â·ì•„ë˜ ì—¬ë°± ì‚´ì§ ì¶•ì†Œ */
.main {padding-top: 1.2rem; padding-bottom: 2rem;}
/* ë²„íŠ¼ ë¼ìš´ë“œ+êµµê¸° */
.stButton>button {border-radius: 10px; font-weight: 600;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ Miromi Retro Filter")
st.caption("Developed by THE PLATFORM COMPANY")

# --------------------------
# Paths
# --------------------------
ROOT = Path(os.getcwd())
LUT_DIR     = ROOT / "filters"
OVERLAY_DIR = ROOT / "overlays"
NOISE_DIR   = ROOT / "noise_videos"
for p in [LUT_DIR, OVERLAY_DIR, NOISE_DIR]:
    p.mkdir(parents=True, exist_ok=True)

# --------------------------
# Utils
# --------------------------
def list_files(folder: Path, exts):
    if not folder.exists():
        return []
    exts = tuple(e.lower() for e in exts)
    return sorted([f.name for f in folder.iterdir() if f.is_file() and f.suffix.lower() in exts], key=str.lower)

def load_overlay_image(name):
    path = str(OVERLAY_DIR / name)
    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # PNG alpha ì§€ì›
    return img

def first_frame_of_video(path: str):
    cap = cv2.VideoCapture(path)
    ok, frame = cap.read()
    cap.release()
    if not ok or frame is None:
        return None
    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

# ---- LUT: í™•ì‹¤í•œ íŒŒì„œ (LUT_3D_SIZE ê¸°ë°˜)
def load_cube_lut(path: str):
    size = None
    data = []
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        for raw in f:
            line = raw.strip()
            if not line or line.startswith("#"):
                continue
            parts = line.split()
            # í—¤ë”
            if parts[0].upper() == "LUT_3D_SIZE":
                size = int(parts[-1])
                continue
            # ë°ì´í„°
            if len(parts) == 3:
                try:
                    r, g, b = map(float, parts)
                    data.append([r, g, b])
                except:
                    pass
    if size is None:
        # fallback: cubeê°€ ì •ë°©ì¼ ë•Œ ë£¨íŠ¸ë¡œ ìœ ì¶”
        n = int(round(len(data) ** (1/3)))
        size = max(2, n)
    arr = np.array(data, dtype=np.float32)
    arr = arr.reshape((size, size, size, 3))           # [R, G, B] ìˆœ
    arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)
    return arr  # RGB ê²°ê³¼í‘œ

# ---- LUT ì ìš©: ê¸°ë³¸ì€ BGR(ê¶Œì¥). í•„ìš” ì‹œ RGB í† ê¸€
def apply_lut_bgr(frame_bgr: np.ndarray, lut_rgb: np.ndarray, mode: str = "BGR"):
    """
    frame_bgr : ì›ë³¸ BGR(0..255, uint8)
    lut_rgb   : LUT[R,G,B] -> (R,G,B)  uint8
    mode      : "BGR"(ê¶Œì¥) | "RGB"
    """
    size = lut_rgb.shape[0]
    if mode == "BGR":
        # BGR í”„ë ˆì„ì—ì„œ R,G,B ì±„ë„ ì¸ë±ìŠ¤ ìƒì„± (LUTì€ RGB ì¸ë±ì‹±)
        r = frame_bgr[..., 2]
        g = frame_bgr[..., 1]
        b = frame_bgr[..., 0]
        idx_r = ((r.astype(np.float32) / 255.0) * (size - 1)).astype(np.int32)
        idx_g = ((g.astype(np.float32) / 255.0) * (size - 1)).astype(np.int32)
        idx_b = ((b.astype(np.float32) / 255.0) * (size - 1)).astype(np.int32)
        out_rgb = lut_rgb[idx_r, idx_g, idx_b]
        out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)
        return out_bgr
    else:
        # í”„ë ˆì„ì„ RGBë¡œ ê°„ì£¼í•˜ì—¬ ê³§ë°”ë¡œ ì¸ë±ì‹± (íŠ¹ìˆ˜ LUT ëŒ€ì‘)
        r = frame_bgr[..., 0]
        g = frame_bgr[..., 1]
        b = frame_bgr[..., 2]
        idx_r = ((r.astype(np.float32) / 255.0) * (size - 1)).astype(np.int32)
        idx_g = ((g.astype(np.float32) / 255.0) * (size - 1)).astype(np.int32)
        idx_b = ((b.astype(np.float32) / 255.0) * (size - 1)).astype(np.int32)
        out_rgb = lut_rgb[idx_r, idx_g, idx_b]
        return cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

def apply_static_grain(frame_bgr, amount=0.0):
    if amount <= 0: 
        return frame_bgr
    h, w = frame_bgr.shape[:2]
    noise = np.random.normal(0, 25, (h, w, 3)).astype(np.float32)  # ê¸°ë³¸ ë…¸ì´ì¦ˆ
    out = np.clip(frame_bgr.astype(np.float32) + noise * amount, 0, 255).astype(np.uint8)
    return out

def apply_dream_blur(frame_bgr, strength=0.0):
    if strength <= 0:
        return frame_bgr
    k = max(1, int(3 + strength * 6))  # 3~9
    if k % 2 == 0: 
        k += 1
    blur = cv2.GaussianBlur(frame_bgr, (k, k), 0)
    # screen blend: 1 - (1-A)(1-B)
    A = frame_bgr.astype(np.float32) / 255.0
    B = blur.astype(np.float32) / 255.0
    screen = 1.0 - (1.0 - A) * (1.0 - B)
    out = (A * (1 - 0.35*strength) + screen * (0.35*strength)) * 255.0
    return np.clip(out, 0, 255).astype(np.uint8)

def apply_overlay(frame_bgr, overlay, opacity=0.3):
    if overlay is None:
        return frame_bgr
    h, w = frame_bgr.shape[:2]
    ov = cv2.resize(overlay, (w, h))
    if ov.shape[2] == 4:  # RGBA
        rgb = ov[..., :3]
        alpha = (ov[..., 3:].astype(np.float32) / 255.0) * opacity
        base = frame_bgr.astype(np.float32)
        rgb_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR).astype(np.float32)
        out = base * (1 - alpha) + rgb_bgr * alpha
        return np.clip(out, 0, 255).astype(np.uint8)
    else:
        # no alpha â†’ ë‹¨ìˆœ ê°€ì¤‘í•©
        ov_bgr = cv2.cvtColor(ov, cv2.COLOR_RGB2BGR)
        return cv2.addWeighted(frame_bgr, 1 - opacity, ov_bgr, opacity, 0)

def blend_moving_noise(frame_bgr, noise_frame_bgr, amount=0.25):
    if noise_frame_bgr is None or amount <= 0:
        return frame_bgr
    noise = cv2.resize(noise_frame_bgr, (frame_bgr.shape[1], frame_bgr.shape[0]))
    # addWeightedë¡œ ì‚´ì§ ì–¹ê¸°
    return cv2.addWeighted(frame_bgr, 1 - amount, noise, amount, 0)

# --------------------------
# Sidebar / Controls
# --------------------------
video_file = st.file_uploader("ğŸ¥ ì˜ìƒ ì—…ë¡œë“œ (MP4/MOV/AVI Â· ìµœëŒ€ 1GB)", type=["mp4", "mov", "avi"])

lut_files = list_files(LUT_DIR, [".cube"])
overlay_files = list_files(OVERLAY_DIR, [".png", ".jpg", ".jpeg"])
noise_files = list_files(NOISE_DIR, [".mp4", ".mov", ".m4v"])

st.subheader("ğŸ¨ LUT & ì´í™íŠ¸")
col1, col2 = st.columns(2)
with col1:
    lut_name = st.selectbox("LUT í”„ë¦¬ì…‹", ["None"] + lut_files, index=0)
    lut_mode = st.radio("LUT ìƒ‰ìƒ ìˆœì„œ", ["BGR (ê¶Œì¥)", "RGB"], horizontal=True, index=0,
                        help="ì–¼êµ´ì´ íŒŒë—ê²Œ ë³´ì´ë©´ BGRì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°ì´ë¯€ë¡œ RGBë¡œ ë°”ê¿” í™•ì¸í•˜ì„¸ìš”.")
with col2:
    fast_mode = st.checkbox("âš¡ ë¹ ë¥¸ ë Œë” (30ì´ˆ ì´ë‚´)", value=True,
                            help="FPSë¥¼ ë‚®ì¶”ê³  í”„ë ˆì„ ì²˜ë¦¬ëŸ‰/í•´ìƒë„ë¥¼ ì•½ê°„ ì¤„ì—¬ ë Œë” ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤. GPUëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤(í´ë¼ìš°ë“œ ì œí•œ).")

st.markdown("### ğŸ“¼ ì˜¤ë²„ë ˆì´ & ë…¸ì´ì¦ˆ")
ov_col, nz_col = st.columns(2)
with ov_col:
    overlay_name = st.selectbox("ì •ì§€ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€", ["None"] + overlay_files, index=0)
    overlay_op = st.slider("ì˜¤ë²„ë ˆì´ ê°•ë„", 0, 10, 3)  # 0~10
    # ì„ íƒí•œ ì˜¤ë²„ë ˆì´ ì¸ë„¤ì¼
    if overlay_name != "None":
        ov_img = load_overlay_image(overlay_name)
        if ov_img is not None:
            st.image(cv2.cvtColor(ov_img[..., :3], cv2.COLOR_BGR2RGB), caption=overlay_name, use_column_width=True)

with nz_col:
    noise_name = st.selectbox("ì›€ì§ì´ëŠ” ë…¸ì´ì¦ˆ(ë¹„ë””ì˜¤)", ["None"] + noise_files, index=0)
    noise_mix = st.slider("ë…¸ì´ì¦ˆ ê°•ë„", 0, 10, 2)
    # ë™ì˜ìƒ ì²« í”„ë ˆì„ ì¸ë„¤ì¼
    if noise_name != "None":
        thumb = first_frame_of_video(str(NOISE_DIR / noise_name))
        if thumb is not None:
            st.image(thumb, caption=f"{noise_name} (thumbnail)", use_column_width=True)

st.markdown("### ğŸšï¸ ê¸°ë³¸ íš¨ê³¼")
c1, c2 = st.columns(2)
with c1:
    grain_amt = st.slider("ê·¸ë ˆì¸(ì •ì§€)", 0, 10, 2)
with c2:
    blur_amt = st.slider("ë“œë¦¼ ë¸”ëŸ¬", 0, 10, 1)

st.divider()
preview_sec = 3
cprev, crun = st.columns([1,1])
btn_preview = cprev.button(f"ğŸ¬ {preview_sec}ì´ˆ ë¯¸ë¦¬ë³´ê¸° ë§Œë“¤ê¸°")
btn_render  = crun.button("ğŸš€ ì „ì²´ ì˜ìƒ ë Œë”ë§")

# --------------------------
# Core processing
# --------------------------
def process_video(src_path: str, out_path: str, full_render: bool):
    cap = cv2.VideoCapture(src_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 1

    # ë¹ ë¥¸ ë Œë”: FPS ë‚®ì¶”ê³ , ì•½ê°„ ìŠ¤ì¼€ì¼ ë‹¤ìš´
    if fast_mode:
        target_fps = min(fps, 18)
        scale = 0.90
    else:
        target_fps = fps
        scale = 1.0

    out_w, out_h = int(width * scale), int(height * scale)
    if out_w < 2 or out_h < 2:
        out_w, out_h = width, height

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(out_path, fourcc, target_fps, (out_w, out_h))

    # ë¯¸ë¦¬ LUT/ì˜¤ë²„ë ˆì´/ë…¸ì´ì¦ˆ ì¤€ë¹„
    lut = None
    if lut_name != "None":
        lut = load_cube_lut(str(LUT_DIR / lut_name))

    ov_img = None
    if overlay_name != "None":
        ov_img = load_overlay_image(overlay_name)

    noise_cap = None
    if noise_name != "None":
        noise_cap = cv2.VideoCapture(str(NOISE_DIR / noise_name))

    max_frames = total
    if not full_render:
        # ë¯¸ë¦¬ë³´ê¸°ëŠ” Nì´ˆê¹Œì§€ë§Œ
        max_frames = int(min(total, preview_sec * fps))

    prog = st.progress(0.0)
    done = 0

    while done < max_frames:
        ok, frame = cap.read()
        if not ok or frame is None:
            break

        # ë¹ ë¥¸ ë Œë”: ìŠ¤ì¼€ì¼ ë‹¤ìš´
        if scale != 1.0:
            frame = cv2.resize(frame, (out_w, out_h), interpolation=cv2.INTER_AREA)

        # 1) LUT
        if lut is not None:
            frame = apply_lut_bgr(frame, lut, "BGR" if "BGR" in lut_mode else "RGB")

        # 2) ì •ì§€ ê·¸ë ˆì¸
        if grain_amt > 0:
            frame = apply_static_grain(frame, grain_amt / 10.0)

        # 3) ë“œë¦¼ ë¸”ëŸ¬
        if blur_amt > 0:
            frame = apply_dream_blur(frame, blur_amt / 10.0)

        # 4) ì •ì§€ ì˜¤ë²„ë ˆì´
        if ov_img is not None:
            frame = apply_overlay(frame, ov_img, opacity=(overlay_op / 10.0))

        # 5) ì›€ì§ì´ëŠ” ë…¸ì´ì¦ˆ
        if noise_cap is not None and noise_mix > 0:
            ok2, nframe = noise_cap.read()
            if not ok2 or nframe is None:
                noise_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                ok2, nframe = noise_cap.read()
            if ok2 and nframe is not None:
                frame = blend_moving_noise(frame, nframe, amount=noise_mix / 10.0)

        writer.write(frame)
        done += 1
        prog.progress(min(1.0, done / max_frames))

        # ë¹ ë¥¸ ë Œë”ì—ì„œ ë„ˆë¬´ ê¸´ ì˜ìƒì˜ ê²½ìš° ì¼ì • í”„ë ˆì„ë§Œ ìƒ˜í”Œë§í•´ ì†ë„ ì¦ê°€
        if fast_mode and full_render and fps > 24:
            # 24fpsë¡œ ë‹¤ìš´ìƒ˜í”Œ(ê°„ë‹¨ í”„ë ˆì„ìŠ¤í‚¤í•‘)
            skip = int(max(0, round(fps / 24) - 1))
            if skip:
                cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_POS_FRAMES) + skip)

    writer.release()
    cap.release()
    if noise_cap is not None:
        noise_cap.release()

def run_pipeline(full_render: bool):
    if video_file is None:
        st.warning("ğŸ“ ì˜ìƒì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    # ì„ì‹œ íŒŒì¼ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_in:
        tmp_in.write(video_file.read())
        src = tmp_in.name
    out = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name

    process_video(src, out, full_render=full_render)

    if full_render:
        st.success("âœ… ë Œë” ì™„ë£Œ!")
        st.video(out)  # ì¸ì•± ì¬ìƒ
        st.download_button("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", open(out, "rb").read(),
                           file_name=f"Miromi_{Path(video_file.name).stem}.mp4",
                           mime="video/mp4")
    else:
        st.success("ğŸ¬ ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì™„ë£Œ (ì•½ 3ì´ˆ)!")
        st.video(out)

# --------------------------
# Actions
# --------------------------
if btn_preview:
    run_pipeline(full_render=False)

if btn_render:
    run_pipeline(full_render=True)
